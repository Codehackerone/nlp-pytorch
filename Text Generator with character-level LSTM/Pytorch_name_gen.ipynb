{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch-name-gen",
      "provenance": [],
      "authorship_tag": "ABX9TyPIhpaRTKZxDeaTeIwsEQjO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Codehackerone/nlp-pytorch/blob/main/Text%20Generator%20with%20character-level%20LSTM/Pytorch_name_gen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import requests\n",
        "\n",
        "url = 'https://parseapi.back4app.com/classes/Complete_List_Names?limit=100000000000&keys=Name'\n",
        "headers = {\n",
        "    'X-Parse-Application-Id': 'zsSkPsDYTc2hmphLjjs9hz2Q3EXmnSxUyXnouj1I',\n",
        "    'X-Parse-Master-Key': '4LuCXgPPXXO2sU5cXm6WwpwzaKyZpo3Wpj4G4xXK'\n",
        "}\n",
        "data = json.loads(requests.get(url, headers=headers).content.decode('utf-8'))\n",
        "names = [i['Name'] for i in data['results']]\n",
        "\n",
        "with open('names.txt', 'w') as f:\n",
        "    f.write('\\n'.join(names))"
      ],
      "metadata": {
        "id": "_BU_-CLTzfCk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unidecode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "om6SViNPzmMz",
        "outputId": "f1d3a4d5-c5d2-4739-9020-e9587da808c3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.4-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 29.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9snGACNdzUZI",
        "outputId": "3f42fffe-aa0d-410b-ef9a-b1355e0577b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Start training\n",
            "Loss: 2.271778076171875\n",
            "AFgerd\n",
            "Karla\n",
            "Wuverne\n",
            "Mucin\n",
            "Dcannne\n",
            "Evela\n",
            "Elene\n",
            "Jornne\n",
            "Leynnmieten\n",
            "Mlalin\n",
            "Ssalin\n",
            "Haole\n",
            "Claiy\n",
            "Wala\n",
            "Ella\n",
            "Loss: 2.401146240234375\n",
            "Aucies\n",
            "Cildel\n",
            "Jomeg\n",
            "irea\n",
            "Albiy\n",
            "Joache\n",
            "Hereclre\n",
            "Fhelle\n",
            "Kaorfta\n",
            "Brex\n",
            "Tandie\n",
            "Noici\n",
            "Jana\n",
            "Jirrel\n",
            "Rilcie\n",
            "De\n",
            "Loss: 2.134099853515625\n",
            "Allo\n",
            "Aan\n",
            "Jadey\n",
            "Saney\n",
            "Jacand\n",
            "Lilly\n",
            "Vincen\n",
            "Adiste\n",
            "Ollieth\n",
            "Relerr\n",
            "Lua\n",
            "Naca\n",
            "Jonega\n",
            "Bery\n",
            "Geloyt\n",
            "Toyrer\n",
            "Shi\n",
            "Loss: 2.059052734375\n",
            "Adie\n",
            "Ceze\n",
            "Ronne\n",
            "Damdall\n",
            "Karo\n",
            "Andaurey\n",
            "Wangie\n",
            "Lene\n",
            "Amorela\n",
            "Adrie\n",
            "Samina\n",
            "Carner\n",
            "Dela\n",
            "Jeason\n",
            "Oris\n",
            "Juline\n",
            "Loss: 1.8622960205078125\n",
            "Aluse\n",
            "Emcyl\n",
            "Matuy\n",
            "Hoenall\n",
            "Tince\n",
            "Laret\n",
            "Emlynd\n",
            "Danoly\n",
            "Frianne\n",
            "Willes\n",
            "Orart\n",
            "Riliette\n",
            "alla\n",
            "Syralina\n",
            "Wicti\n",
            "Loss: 1.7917508544921874\n",
            "Azine\n",
            "Charla\n",
            "Beverl\n",
            "Danna\n",
            "Emirie\n",
            "Juffub\n",
            "Olleyne\n",
            "LaLey\n",
            "Lidia\n",
            "Mider\n",
            "Riginer\n",
            "Bendabge\n",
            "Dadie\n",
            "Sherty\n",
            "Pelev\n",
            "Loss: 2.088212890625\n",
            "Aberne\n",
            "Clille\n",
            "Becel\n",
            "Eu\n",
            "Berid\n",
            "Miney\n",
            "Vade\n",
            "Saunie\n",
            "Pelle\n",
            "Chirlina\n",
            "Rosey\n",
            "Kirgara\n",
            "Erneg\n",
            "Marian\n",
            "Daria\n",
            "Morgia\n",
            "Loss: 2.1648720703125\n",
            "Auman\n",
            "Alanne\n",
            "Edy\n",
            "Ellinie\n",
            "Jowis\n",
            "Lema\n",
            "BaKgura\n",
            "Chod\n",
            "Benta\n",
            "Maline\n",
            "Charlene\n",
            "Camonie\n",
            "Elenia\n",
            "Eda\n",
            "Edrine\n",
            "Burg\n",
            "Loss: 1.8475416259765625\n",
            "Artonn\n",
            "Kriston\n",
            "Marwer\n",
            "Wardence\n",
            "Brance\n",
            "Daronte\n",
            "Coma\n",
            "Robertt\n",
            "Ina\n",
            "Loriance\n",
            "Virna\n",
            "Mefrene\n",
            "Elicha\n",
            "Peta\n",
            "Edn\n",
            "Loss: 1.6509302978515625\n",
            "Arce\n",
            "Freda\n",
            "Gilandra\n",
            "Alvinia\n",
            "Marinna\n",
            "ulvin\n",
            "Elvin\n",
            "Terrince\n",
            "Oris\n",
            "Robdy\n",
            "Culia\n",
            "Picelia\n",
            "Willes\n",
            "Norvin\n",
            "Arle\n",
            "\n",
            "Loss: 1.9123759765625\n",
            "Adando\n",
            "Harrella\n",
            "Anton\n",
            "Alphonne\n",
            "Camil\n",
            "Berl\n",
            "Freddy\n",
            "Marthy\n",
            "Mina\n",
            "Domert\n",
            "Omari\n",
            "Katharine\n",
            "Ludide\n",
            "Derlen\n",
            "Reo\n",
            "Loss: 1.6060374755859375\n",
            "Alece\n",
            "Anretta\n",
            "Jyngel\n",
            "Gabsas\n",
            "Francis\n",
            "Ronal\n",
            "Burse\n",
            "Kryd\n",
            "Doshae\n",
            "Wil\n",
            "Embi\n",
            "Ellisa\n",
            "Maria\n",
            "Concell\n",
            "Mary\n",
            "Rean\n",
            "G\n",
            "Loss: 1.6979573974609374\n",
            "Axond\n",
            "Randol\n",
            "Fances\n",
            "Conny\n",
            "Erristine\n",
            "Obel\n",
            "Zelnia\n",
            "Odella\n",
            "Micke\n",
            "Lovanne\n",
            "Marmen\n",
            "Eddy\n",
            "Tommian\n",
            "Elisza\n",
            "Bodgi\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-ac3b5455b3cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0mgennames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m \u001b[0mgennames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-ac3b5455b3cf>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import string\n",
        "import random\n",
        "import sys\n",
        "import unidecode\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Get characters from string.printable\n",
        "all_characters = string.printable\n",
        "n_characters = len(all_characters)\n",
        "\n",
        "# Read large text file\n",
        "file = unidecode.unidecode(open('./names.txt').read())\n",
        "\n",
        "\n",
        "# Model\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(RNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embed = nn.Embedding(input_size, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x, hidden, cell):\n",
        "        out = self.embed(x)\n",
        "        out, (hidden, cell) = self.lstm(out.unsqueeze(1), (hidden, cell))\n",
        "        out = self.fc(out.reshape(out.shape[0], -1))\n",
        "        return out, (hidden, cell)\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "        cell = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "        return hidden, cell\n",
        "\n",
        "\n",
        "class Generator():\n",
        "    def __init__(self):\n",
        "        self.chunk_len = 250\n",
        "        self.num_epochs = 5000\n",
        "        self.batch_size = 1\n",
        "        self.print_every = 50\n",
        "        self.hidden_size = 256\n",
        "        self.num_layers = 2\n",
        "        self.lr = 0.003\n",
        "\n",
        "    # Take a char and map it to a vector\n",
        "    def char_tensor(self, string):\n",
        "        tensor = torch.zeros(len(string)).long()\n",
        "        for c in range(len(string)):\n",
        "            tensor[c] = all_characters.index(string[c])\n",
        "        return tensor\n",
        "\n",
        "    def get_random_batch(self):\n",
        "        start_idx = random.randint(0, len(file) - self.chunk_len)\n",
        "        end_idx = start_idx + self.chunk_len + 1\n",
        "        text_str = file[start_idx:end_idx]\n",
        "        text_input = torch.zeros(self.batch_size, self.chunk_len)\n",
        "        text_target = torch.zeros(self.batch_size, self.chunk_len)\n",
        "\n",
        "        # Obtain a char to input and set the prediction to target\n",
        "        for i in range(self.batch_size):\n",
        "            text_input[i, :] = self.char_tensor(text_str[:-1])\n",
        "            text_target[i, :] = self.char_tensor(text_str[1:])\n",
        "\n",
        "        return text_input.long(), text_target.long()\n",
        "\n",
        "    def generate(self, initial_str='A', prediction_len=100, temperature=0.85):\n",
        "        # temp is how risky rnn could be. If temp is lower, it could predict and and and or or etc\n",
        "        hidden, cell = self.rnn.init_hidden(batch_size=self.batch_size)\n",
        "        initial_input = self.char_tensor(initial_str)\n",
        "        predicted = initial_str\n",
        "\n",
        "        for p in range(len(initial_str) - 1):\n",
        "            # random values\n",
        "            _, (hidden, cell) = self.rnn(initial_input[p].view(1).to(device), hidden, cell)\n",
        "\n",
        "        last_char = initial_input[-1]\n",
        "        # Actual Predictions\n",
        "        for p in range(prediction_len):\n",
        "            output, (hidden, cell) = self.rnn(last_char.view(1).to(device), hidden, cell)\n",
        "            output_dist = output.data.view(-1).div(temperature).exp() # eliminate common names\n",
        "            top_char = torch.multinomial(output_dist, 1)[0] # not taking the highest probability\n",
        "            predicted_char = all_characters[top_char]\n",
        "            predicted += predicted_char\n",
        "            last_char = self.char_tensor(predicted_char)\n",
        "\n",
        "        return predicted\n",
        "\n",
        "    def train(self):\n",
        "        self.rnn = RNN(n_characters, self.hidden_size, self.num_layers, n_characters).to(device)\n",
        "        optimizer = torch.optim.Adam(self.rnn.parameters(), lr=self.lr)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        writer = SummaryWriter(f'runs/names0') # for tensorboard\n",
        "\n",
        "        print(\"=> Start training\")\n",
        "\n",
        "        for epoch in range(1, self.num_epochs + 1):\n",
        "            inp, target = self.get_random_batch()\n",
        "            hidden, cell = self.rnn.init_hidden(batch_size=self.batch_size)\n",
        "\n",
        "            self.rnn.zero_grad()\n",
        "            loss = 0\n",
        "            inp = inp.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            for c in range(self.chunk_len):\n",
        "                output, (hidden, cell) = self.rnn(inp[:, c], hidden, cell)\n",
        "                loss += criterion(output, target[:, c])\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss = loss.item()/self.chunk_len\n",
        "\n",
        "            if epoch % self.print_every == 0:\n",
        "                print(f'Loss: {loss}')\n",
        "                print(self.generate())\n",
        "\n",
        "            writer.add_scalar('Training Loss', loss, global_step=epoch)\n",
        "\n",
        "\n",
        "gennames = Generator()\n",
        "gennames.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Zp3quDr8zpUr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}